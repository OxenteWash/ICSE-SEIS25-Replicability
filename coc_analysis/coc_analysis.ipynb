{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from JSON file\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Access configuration variables\n",
    "base_dir = config[\"base_dir\"]\n",
    "patterns = config[\"patterns\"]\n",
    "last_mod_coc = config[\"last_mod_coc\"]\n",
    "flags =config[\"flags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\scobosga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\scobosga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\scobosga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources for text processing:\n",
    "# - 'punkt_tab': Tokenizer models for splitting text into sentences and words.\n",
    "# - 'averaged_perceptron_tagger_eng': Pretrained model for part-of-speech tagging (specific to English).\n",
    "# - 'wordnet': Lexical database for English, used for lemmatization and word relationships.\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Iterate through each language directory in the base directory\n",
    "for language in os.listdir(base_dir):\n",
    "    language_dir = os.path.join(base_dir, language)\n",
    "    if os.path.isdir(language_dir):  # Check if the path is a directory\n",
    "        coc_files_count = 0  # Initialize count for code of conduct files\n",
    "\n",
    "        # Iterate through each repository in the language directory\n",
    "        for repo in os.listdir(language_dir):\n",
    "            repo_dir = os.path.join(language_dir, repo)\n",
    "            if os.path.isdir(repo_dir):  # Check if the path is a repository directory\n",
    "                # Count files matching any pattern in the repository\n",
    "                coc_files_count += len([\n",
    "                    file for file in os.listdir(repo_dir) \n",
    "                    if any(pattern in file.lower() for pattern in patterns)\n",
    "                ])\n",
    "\n",
    "        # Append the language and its code of conduct file count to the data list\n",
    "        data.append({\"Language\": language, \"Presence(#)\": coc_files_count})\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df_presence = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the percentage of presence for each language\n",
    "df_presence[\"Presence(%)\"] = (df_presence[\"Presence(#)\"] / 1000) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Iterate through each language directory in the base directory\n",
    "for language in os.listdir(base_dir):\n",
    "    language_dir = os.path.join(base_dir, language)\n",
    "    if os.path.isdir(language_dir):  # Check if the path is a directory\n",
    "        coc_files_count = 0  # Initialize count for code of conduct files\n",
    "        with_corpus_count = 0  # Initialize count for files with significant content\n",
    "\n",
    "        # Iterate through each repository in the language directory\n",
    "        for repo in os.listdir(language_dir):\n",
    "            repo_dir = os.path.join(language_dir, repo)\n",
    "            if os.path.isdir(repo_dir):  # Check if the path is a repository directory\n",
    "                # Iterate through files in the repository\n",
    "                for file in os.listdir(repo_dir):\n",
    "                    # Check if the file matches any specified pattern\n",
    "                    if any(pattern in file.lower() for pattern in patterns):\n",
    "                        coc_files_count += 1  # Increment count for code of conduct files\n",
    "                        coc_file_path = os.path.join(repo_dir, file)\n",
    "                        try:\n",
    "                            # Read the file content to check if it contains more than 5 lines\n",
    "                            with open(coc_file_path, 'r', encoding='utf-8') as f:\n",
    "                                lines = f.readlines()\n",
    "                                if len(lines) > 5: \n",
    "                                    with_corpus_count += 1  # Increment count for files with significant content\n",
    "                        except Exception as e:\n",
    "                            # Print error message if the file cannot be read\n",
    "                            print(f\"Error reading the file {coc_file_path}: {e}\")\n",
    "\n",
    "        # Append results for the language to the data list\n",
    "        data.append({\n",
    "            \"Language\": language,\n",
    "            \"Content(#)\": with_corpus_count\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df_content = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the percentage of repositories with significant content\n",
    "df_content[\"Content(%)\"] = (df_content[\"Content(#)\"] / 1000) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References to CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans a given text by applying the following steps:\n",
    "    \n",
    "    1. Converts all characters to lowercase.\n",
    "    2. Removes all punctuation marks.\n",
    "    3. Replaces multiple whitespace characters with a single space.\n",
    "    4. Strips leading and trailing spaces.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned and normalized text.\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove all punctuation marks using a regex pattern\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    \n",
    "    # Replace multiple whitespace characters with a single space and strip leading/trailing spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Code of Conduct files from repositories\n",
    "data = []\n",
    "\n",
    "for language in os.listdir(base_dir):\n",
    "    language_dir = os.path.join(base_dir, language)\n",
    "    if os.path.isdir(language_dir):  # Ensure the path is a valid directory\n",
    "        for repo in os.listdir(language_dir):  # Iterate through repositories for each language\n",
    "            repo_dir = os.path.join(language_dir, repo)\n",
    "            if os.path.isdir(repo_dir):  # Ensure the repository path is valid\n",
    "                for file in os.listdir(repo_dir):  # Iterate through files in the repository\n",
    "                    if any(pattern in file.lower() for pattern in patterns):  # Match file names against patterns\n",
    "                        file_path = os.path.join(repo_dir, file)\n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:  # Read file content\n",
    "                            content = f.read()\n",
    "                        data.append({\"Language\": language, \"Repo_Name\": repo, \"CoC_Content\": content})\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df_cc = pd.DataFrame(data)\n",
    "\n",
    "# Filter CoC files with at least 5 lines\n",
    "df_cc['Line_Count'] = df_cc['CoC_Content'].apply(lambda x: len(x.split('\\n')))\n",
    "df_cc = df_cc[df_cc['Line_Count'] >= 5]\n",
    "df_cc = df_cc.drop(columns=['Line_Count'])  # Drop the line count column after filtering\n",
    "\n",
    "# Clean the content of the CoC files\n",
    "df_cc['CoC_Content_Clean'] = df_cc['CoC_Content'].apply(clean_text)\n",
    "\n",
    "# Calculate the percentage of repositories referencing \"Contributor Covenant\" for each language\n",
    "data = []\n",
    "\n",
    "languages = df_cc['Language'].unique()  # Identify unique programming languages\n",
    "\n",
    "for language in languages:\n",
    "    df_language = df_cc[df_cc['Language'] == language]  # Filter rows for the current language\n",
    "    total_rows = len(df_language)  # Total repositories with CoC files for the language\n",
    "    rows_with_cc = df_language['CoC_Content_Clean'].str.contains(\"contributor covenant\", case=False, na=False).sum()\n",
    "    percentage = (rows_with_cc / total_rows) * 100  # Calculate percentage of repositories with the reference\n",
    "    data.append({\n",
    "        'Language': language,\n",
    "        'r_cc(%)': percentage  # Add the percentage to the results\n",
    "    })\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "df_r_cc = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Presence(#)</th>\n",
       "      <th>Presence(%)</th>\n",
       "      <th>Content(#)</th>\n",
       "      <th>Content(%)</th>\n",
       "      <th>r_cc(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>101</td>\n",
       "      <td>10.1</td>\n",
       "      <td>87</td>\n",
       "      <td>8.7</td>\n",
       "      <td>80.219780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C#</td>\n",
       "      <td>213</td>\n",
       "      <td>21.3</td>\n",
       "      <td>178</td>\n",
       "      <td>17.8</td>\n",
       "      <td>86.934673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C++</td>\n",
       "      <td>171</td>\n",
       "      <td>17.1</td>\n",
       "      <td>148</td>\n",
       "      <td>14.8</td>\n",
       "      <td>74.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go</td>\n",
       "      <td>290</td>\n",
       "      <td>29.0</td>\n",
       "      <td>208</td>\n",
       "      <td>20.8</td>\n",
       "      <td>86.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java</td>\n",
       "      <td>107</td>\n",
       "      <td>10.7</td>\n",
       "      <td>94</td>\n",
       "      <td>9.4</td>\n",
       "      <td>80.198020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>242</td>\n",
       "      <td>24.2</td>\n",
       "      <td>215</td>\n",
       "      <td>21.5</td>\n",
       "      <td>87.782805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PHP</td>\n",
       "      <td>117</td>\n",
       "      <td>11.7</td>\n",
       "      <td>110</td>\n",
       "      <td>11.0</td>\n",
       "      <td>86.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python</td>\n",
       "      <td>223</td>\n",
       "      <td>22.3</td>\n",
       "      <td>193</td>\n",
       "      <td>19.3</td>\n",
       "      <td>78.325123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ruby</td>\n",
       "      <td>190</td>\n",
       "      <td>19.0</td>\n",
       "      <td>176</td>\n",
       "      <td>17.6</td>\n",
       "      <td>86.592179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rust</td>\n",
       "      <td>230</td>\n",
       "      <td>23.0</td>\n",
       "      <td>202</td>\n",
       "      <td>20.2</td>\n",
       "      <td>83.732057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Scala</td>\n",
       "      <td>109</td>\n",
       "      <td>10.9</td>\n",
       "      <td>97</td>\n",
       "      <td>9.7</td>\n",
       "      <td>47.524752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>325</td>\n",
       "      <td>32.5</td>\n",
       "      <td>302</td>\n",
       "      <td>30.2</td>\n",
       "      <td>90.584416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Language  Presence(#)  Presence(%)  Content(#)  Content(%)    r_cc(%)\n",
       "0            C          101         10.1          87         8.7  80.219780\n",
       "1           C#          213         21.3         178        17.8  86.934673\n",
       "2          C++          171         17.1         148        14.8  74.193548\n",
       "3           Go          290         29.0         208        20.8  86.363636\n",
       "4         Java          107         10.7          94         9.4  80.198020\n",
       "5   JavaScript          242         24.2         215        21.5  87.782805\n",
       "6          PHP          117         11.7         110        11.0  86.607143\n",
       "7       Python          223         22.3         193        19.3  78.325123\n",
       "8         Ruby          190         19.0         176        17.6  86.592179\n",
       "9         Rust          230         23.0         202        20.2  83.732057\n",
       "10       Scala          109         10.9          97         9.7  47.524752\n",
       "11  TypeScript          325         32.5         302        30.2  90.584416"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the DataFrames `df_presence` and `df_content` based on the \"Language\" column using an outer join\n",
    "df_combined = pd.merge(df_presence, df_content, on=\"Language\", how=\"outer\")\n",
    "\n",
    "# Add `df_r_cc` to the combined DataFrame by merging it on the \"Language\" column\n",
    "df_combined = pd.merge(df_combined, df_r_cc, on=\"Language\", how=\"outer\")\n",
    "\n",
    "# Display the resulting combined DataFrame\n",
    "df_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIGURE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>f_coc_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.528550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C#</td>\n",
       "      <td>0.578754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C++</td>\n",
       "      <td>0.505745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go</td>\n",
       "      <td>0.565003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java</td>\n",
       "      <td>0.500426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>0.458285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PHP</td>\n",
       "      <td>0.466806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python</td>\n",
       "      <td>0.554655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ruby</td>\n",
       "      <td>0.511256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rust</td>\n",
       "      <td>0.647693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Scala</td>\n",
       "      <td>0.580749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>0.540075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Language  f_coc_average\n",
       "0            C       0.528550\n",
       "1           C#       0.578754\n",
       "2          C++       0.505745\n",
       "3           Go       0.565003\n",
       "4         Java       0.500426\n",
       "5   JavaScript       0.458285\n",
       "6          PHP       0.466806\n",
       "7       Python       0.554655\n",
       "8         Ruby       0.511256\n",
       "9         Rust       0.647693\n",
       "10       Scala       0.580749\n",
       "11  TypeScript       0.540075"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the input CSV file\n",
    "df_f_coc = pd.read_csv(last_mod_coc)\n",
    "\n",
    "# Convert relevant date columns to datetime format, handling errors gracefully\n",
    "df_f_coc['Code_of_Conduct_Last_Modified'] = pd.to_datetime(df_f_coc['Code_of_Conduct_Last_Modified'], errors='coerce')\n",
    "df_f_coc['Last_Commit_Date'] = pd.to_datetime(df_f_coc['Last_Commit_Date'], errors='coerce')\n",
    "df_f_coc['Creation_Date'] = pd.to_datetime(df_f_coc['Creation_Date'], errors='coerce')\n",
    "\n",
    "# Drop rows where any of the key date columns are missing and create a filtered copy\n",
    "df_filtered = df_f_coc.dropna(subset=['Code_of_Conduct_Last_Modified', 'Last_Commit_Date', 'Creation_Date']).copy()\n",
    "\n",
    "# Define the threshold for active repositories (last commit within the last 6 months)\n",
    "active_threshold = pd.Timestamp.now() - pd.DateOffset(months=6)\n",
    "\n",
    "# Add a column to indicate if a repository is active\n",
    "df_filtered.loc[:, 'Is_Active'] = df_filtered['Last_Commit_Date'] >= active_threshold\n",
    "\n",
    "# Calculate the lifetime of each repository in years\n",
    "df_filtered.loc[:, 'Repo_Lifetime_Years'] = (df_filtered['Last_Commit_Date'] - df_filtered['Creation_Date']).apply(lambda x: x.days / 365)\n",
    "\n",
    "# Calculate the time difference in years between the last commit and the last modification of the code of conduct\n",
    "df_filtered.loc[:, 'Years_Difference'] = (df_filtered['Last_Commit_Date'] - df_filtered['Code_of_Conduct_Last_Modified']).apply(lambda x: x.days / 365)\n",
    "\n",
    "# Calculate the freshness of the code of conduct (f_coc) as the ratio of Years_Difference to Repo_Lifetime_Years\n",
    "df_filtered['f_coc'] = df_filtered['Years_Difference'] / df_filtered['Repo_Lifetime_Years']\n",
    "\n",
    "# Calculate the mean freshness ratio (f_coc) grouped by language\n",
    "mean_ratio_by_language = df_filtered.groupby('Language')['f_coc'].mean().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "mean_ratio_by_language.columns = ['Language', 'f_coc_average']\n",
    "\n",
    "# Display the resulting DataFrame \n",
    "mean_ratio_by_language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"\n",
    "    Maps a word's part-of-speech (POS) tag to the first character \n",
    "    that the WordNet lemmatizer accepts.\n",
    "    \n",
    "    Parameters:\n",
    "        word (str): The word to analyze.\n",
    "    \n",
    "    Returns:\n",
    "        str: A corresponding WordNet POS tag ('a', 'n', 'v', 'r'), defaults to 'n' (noun).\n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Lemmatizes a given text by reducing words to their base forms using POS tagging.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text to lemmatize.\n",
    "    \n",
    "    Returns:\n",
    "        str: The lemmatized version of the input text.\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens])\n",
    "    return lemmatized_text\n",
    "\n",
    "def find_flags(text, flags):\n",
    "    \"\"\"\n",
    "    Identifies specific flags (keywords) within the given text.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text to analyze.\n",
    "        flags (dict): A dictionary with flag identifiers as keys and lists of keywords as values.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary of flags with their matched keywords from the text.\n",
    "    \"\"\"\n",
    "    lemmatized_text = lemmatize_text(text)\n",
    "    results = {}\n",
    "    for flag, keywords in flags.items():\n",
    "        for keyword in keywords:\n",
    "            lemmatized_keyword = lemmatize_text(keyword)\n",
    "            if re.search(r'\\b' + re.escape(lemmatized_keyword) + r'\\b', lemmatized_text, re.IGNORECASE):\n",
    "                if flag not in results:\n",
    "                    results[flag] = []\n",
    "                results[flag].append(keyword)\n",
    "    return results\n",
    "\n",
    "def safe_eval(val):\n",
    "    \"\"\"\n",
    "    Safely evaluates a string representation of a Python literal (e.g., list, dict) into its Python equivalent.\n",
    "\n",
    "    Parameters:\n",
    "        val (str): The string to evaluate.\n",
    "    \n",
    "    Returns:\n",
    "        object: The evaluated Python object, or the original value if not a string.\n",
    "    \"\"\"\n",
    "    if isinstance(val, str):\n",
    "        return ast.literal_eval(val)\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Flag</th>\n",
       "      <th>Language</th>\n",
       "      <th>F1</th>\n",
       "      <th>F10</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>89.16</td>\n",
       "      <td>87.95</td>\n",
       "      <td>96.39</td>\n",
       "      <td>87.95</td>\n",
       "      <td>32.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>95.18</td>\n",
       "      <td>98.80</td>\n",
       "      <td>96.39</td>\n",
       "      <td>93.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C#</td>\n",
       "      <td>91.41</td>\n",
       "      <td>91.41</td>\n",
       "      <td>93.75</td>\n",
       "      <td>91.41</td>\n",
       "      <td>23.44</td>\n",
       "      <td>91.41</td>\n",
       "      <td>98.44</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C++</td>\n",
       "      <td>86.61</td>\n",
       "      <td>83.46</td>\n",
       "      <td>93.70</td>\n",
       "      <td>83.46</td>\n",
       "      <td>28.35</td>\n",
       "      <td>81.89</td>\n",
       "      <td>93.70</td>\n",
       "      <td>96.85</td>\n",
       "      <td>99.21</td>\n",
       "      <td>91.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go</td>\n",
       "      <td>88.78</td>\n",
       "      <td>84.88</td>\n",
       "      <td>89.27</td>\n",
       "      <td>84.88</td>\n",
       "      <td>32.20</td>\n",
       "      <td>84.88</td>\n",
       "      <td>93.66</td>\n",
       "      <td>94.63</td>\n",
       "      <td>98.05</td>\n",
       "      <td>92.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java</td>\n",
       "      <td>85.23</td>\n",
       "      <td>84.09</td>\n",
       "      <td>89.77</td>\n",
       "      <td>85.23</td>\n",
       "      <td>20.45</td>\n",
       "      <td>85.23</td>\n",
       "      <td>96.59</td>\n",
       "      <td>97.73</td>\n",
       "      <td>98.86</td>\n",
       "      <td>95.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>90.24</td>\n",
       "      <td>86.83</td>\n",
       "      <td>90.73</td>\n",
       "      <td>86.34</td>\n",
       "      <td>22.44</td>\n",
       "      <td>86.83</td>\n",
       "      <td>96.59</td>\n",
       "      <td>98.05</td>\n",
       "      <td>99.51</td>\n",
       "      <td>92.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PHP</td>\n",
       "      <td>81.31</td>\n",
       "      <td>81.31</td>\n",
       "      <td>89.72</td>\n",
       "      <td>83.18</td>\n",
       "      <td>19.63</td>\n",
       "      <td>83.18</td>\n",
       "      <td>89.72</td>\n",
       "      <td>96.26</td>\n",
       "      <td>94.39</td>\n",
       "      <td>89.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python</td>\n",
       "      <td>93.10</td>\n",
       "      <td>88.51</td>\n",
       "      <td>93.10</td>\n",
       "      <td>87.93</td>\n",
       "      <td>36.21</td>\n",
       "      <td>85.63</td>\n",
       "      <td>93.10</td>\n",
       "      <td>94.83</td>\n",
       "      <td>98.28</td>\n",
       "      <td>91.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ruby</td>\n",
       "      <td>69.64</td>\n",
       "      <td>68.45</td>\n",
       "      <td>72.02</td>\n",
       "      <td>69.64</td>\n",
       "      <td>15.48</td>\n",
       "      <td>68.45</td>\n",
       "      <td>95.24</td>\n",
       "      <td>97.02</td>\n",
       "      <td>99.40</td>\n",
       "      <td>85.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rust</td>\n",
       "      <td>96.30</td>\n",
       "      <td>83.07</td>\n",
       "      <td>84.66</td>\n",
       "      <td>84.13</td>\n",
       "      <td>51.32</td>\n",
       "      <td>83.60</td>\n",
       "      <td>84.13</td>\n",
       "      <td>96.83</td>\n",
       "      <td>98.94</td>\n",
       "      <td>84.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Scala</td>\n",
       "      <td>64.56</td>\n",
       "      <td>58.23</td>\n",
       "      <td>62.03</td>\n",
       "      <td>58.23</td>\n",
       "      <td>13.92</td>\n",
       "      <td>58.23</td>\n",
       "      <td>63.29</td>\n",
       "      <td>64.56</td>\n",
       "      <td>100.00</td>\n",
       "      <td>59.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>91.44</td>\n",
       "      <td>89.38</td>\n",
       "      <td>92.47</td>\n",
       "      <td>90.41</td>\n",
       "      <td>35.96</td>\n",
       "      <td>88.36</td>\n",
       "      <td>95.89</td>\n",
       "      <td>98.29</td>\n",
       "      <td>99.66</td>\n",
       "      <td>94.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Flag    Language     F1    F10     F2     F3     F4     F5     F6      F7  \\\n",
       "0              C  89.16  87.95  96.39  87.95  32.53  89.16  95.18   98.80   \n",
       "1             C#  91.41  91.41  93.75  91.41  23.44  91.41  98.44  100.00   \n",
       "2            C++  86.61  83.46  93.70  83.46  28.35  81.89  93.70   96.85   \n",
       "3             Go  88.78  84.88  89.27  84.88  32.20  84.88  93.66   94.63   \n",
       "4           Java  85.23  84.09  89.77  85.23  20.45  85.23  96.59   97.73   \n",
       "5     JavaScript  90.24  86.83  90.73  86.34  22.44  86.83  96.59   98.05   \n",
       "6            PHP  81.31  81.31  89.72  83.18  19.63  83.18  89.72   96.26   \n",
       "7         Python  93.10  88.51  93.10  87.93  36.21  85.63  93.10   94.83   \n",
       "8           Ruby  69.64  68.45  72.02  69.64  15.48  68.45  95.24   97.02   \n",
       "9           Rust  96.30  83.07  84.66  84.13  51.32  83.60  84.13   96.83   \n",
       "10         Scala  64.56  58.23  62.03  58.23  13.92  58.23  63.29   64.56   \n",
       "11    TypeScript  91.44  89.38  92.47  90.41  35.96  88.36  95.89   98.29   \n",
       "\n",
       "Flag      F8     F9  \n",
       "0      96.39  93.98  \n",
       "1     100.00  99.22  \n",
       "2      99.21  91.34  \n",
       "3      98.05  92.20  \n",
       "4      98.86  95.45  \n",
       "5      99.51  92.68  \n",
       "6      94.39  89.72  \n",
       "7      98.28  91.38  \n",
       "8      99.40  85.12  \n",
       "9      98.94  84.66  \n",
       "10    100.00  59.49  \n",
       "11     99.66  94.18  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the find_flags function to clean content and extract matched flags\n",
    "df_cc['Flags'] = df_cc['CoC_Content_Clean'].apply(lambda text: find_flags(text, flags))\n",
    "\n",
    "# Safely evaluate the extracted flags (convert string representations of dicts/lists into Python objects)\n",
    "df_cc['Flags'] = df_cc['Flags'].apply(safe_eval)\n",
    "\n",
    "# Filter out rows where no flags were identified\n",
    "df_cc = df_cc[df_cc['Flags'].apply(lambda x: bool(x))]\n",
    "\n",
    "# Initialize dictionaries to store counts and percentages\n",
    "flag_counts_by_language = {}\n",
    "total_records_by_language = df_cc['Language'].value_counts().to_dict()\n",
    "\n",
    "# Calculate the counts of each flag by language\n",
    "for _, row in df_cc.iterrows():\n",
    "    language = row['Language']\n",
    "    flags = row['Flags']\n",
    "    if language not in flag_counts_by_language:\n",
    "        flag_counts_by_language[language] = {}\n",
    "    for flag, keywords in flags.items():\n",
    "        if flag not in flag_counts_by_language[language]:\n",
    "            flag_counts_by_language[language][flag] = 0\n",
    "        flag_counts_by_language[language][flag] += 1\n",
    "\n",
    "# Calculate percentages of each flag per language\n",
    "flag_percentages_by_language = {}\n",
    "for language, flag_counts in flag_counts_by_language.items():\n",
    "    total_records = total_records_by_language[language]\n",
    "    flag_percentages_by_language[language] = {flag: (count / total_records) * 100 for flag, count in flag_counts.items()}\n",
    "\n",
    "# Convert flag percentages to a list of dictionaries for DataFrame creation\n",
    "flag_percentages_list = []\n",
    "for language, flag_percentages in flag_percentages_by_language.items():\n",
    "    for flag, percentage in flag_percentages.items():\n",
    "        flag_percentages_list.append({'Language': language, 'Flag': flag, 'Percentage': round(percentage, 2)})\n",
    "\n",
    "# Create a DataFrame to hold the flag percentages\n",
    "flag_percentages_df = pd.DataFrame(flag_percentages_list)\n",
    "\n",
    "# Pivot the DataFrame to structure data with one row per language and one column per flag\n",
    "pivot_df = flag_percentages_df.pivot(index='Language', columns='Flag', values='Percentage').reset_index()\n",
    "\n",
    "# Display the final pivot table\n",
    "pivot_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
